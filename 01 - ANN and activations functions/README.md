# Solving the XOR problem

This simple notebooks aims at showing the importance of activation functions in neural networks. 
We will solve the XOR problem which is a non linear classification problem and show that linear can only achieve linear.
We will try several activations functions: Linear, Tanh, ReLU, Sigmo√Ød for deepand shallow network.