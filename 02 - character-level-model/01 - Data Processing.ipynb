{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa882cbc-1106-4806-aad2-374f3d5bae42",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "The goal of this notebook is to preprocess all code files in the **openpyxl** librairy. We will create a generator that go through all files and exhaust the first lines of each module containing import and module description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8cede9-63cb-43d5-8863-a278224e3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5362d9e8-84a7-4f30-b155-2fa2b306dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"openpyxl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7391bcf-39b4-4fb0-b0f5-3575b8a87886",
   "metadata": {},
   "source": [
    "### 1. Create iterator pipeline for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0296d5-814a-4721-a0f7-783394997bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_filepath(base_dir):\n",
    "    \"\"\" Find all filenames in a directory that match a pattern \"\"\"\n",
    "    for root, dirs, files in os.walk(base_dir, topdown=True):\n",
    "        for file in files:\n",
    "            if '.pyc' not in file and '__' not in file and '.pyd' not in file:\n",
    "                fpath = os.path.join(root, file)\n",
    "                yield(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "141c4b76-96e7-4139-a5dc-10aa9181be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_opener(filenames):\n",
    "    \"\"\"\n",
    "    Open a sequence of filenames one at a time producing a file object. \n",
    "    File is immediately closed prior proceeding to the next iteration.\n",
    "    \"\"\"\n",
    "    for filename in filenames:\n",
    "        f = open(filename, 'r')\n",
    "        yield f\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821a725c-66bc-4a37-9ed6-394e3ae2f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_reader(file):\n",
    "    \"\"\" \n",
    "    Read a file object.\n",
    "    Exhaust unnecessary lines when reading a file object \n",
    "    \"\"\"\n",
    "    # exhaust unecessary lines at the top of the files\n",
    "    \n",
    "    # class or def followed by anay characcters followed by semicolon\n",
    "    pattern = r'(class|def)(.*):' \n",
    "    for line in file:\n",
    "        if re.search(pattern, line):\n",
    "            break\n",
    "            \n",
    "    # yield only if last line is a class or function definition       \n",
    "    if re.search(pattern, line):\n",
    "        yield line\n",
    "        \n",
    "        for line in file:\n",
    "            yield line\n",
    "\n",
    "        yield '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428c9770-9ad0-4700-a38a-bdd98eac0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_gen(iterators):\n",
    "    \"\"\" \n",
    "    Concatenate all iterators \n",
    "    The main goal is to yield from file at opening prior clossing them\n",
    "    \"\"\"\n",
    "    for it in iterators:\n",
    "        yield from it # yield file from gen_opener which will be close after being exhausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12594b60-f4ab-4231-9d4a-092fc2bfe935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipeline\n",
    "filenames = gen_filepath(base_dir)\n",
    "files = gen_opener(filenames)\n",
    "inside_files = concat_gen(files) # yield from files then close them\n",
    "lines = gen_reader(inside_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44c0074-3408-4827-b690-03e49aeee35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There ar 28806 lines total.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for line in lines:\n",
    "    counter+=1\n",
    "print(f\"There ar {counter} lines total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da5dfb-0a6d-4729-ac3a-c1b59d8777c7",
   "metadata": {},
   "source": [
    "### 2. Concatenate all lines in a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fd545-0ea6-4262-a7d9-c1ba1f5fc77a",
   "metadata": {},
   "source": [
    "Here we generate a single file containing all the lines of code. We won't really use the generator pipeline as we are going to learn from random chunk of text. We need to process all the text at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d4759a-2bf3-4e92-8f95-4cbe26c35077",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = gen_filepath(base_dir)\n",
    "files = gen_opener(filenames)\n",
    "inside_files = concat_gen(files) # yield from files then close them\n",
    "lines = gen_reader(inside_files)\n",
    "\n",
    "# concatenate all in one text file\n",
    "with open('openpyxl.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe9ea0-d6de-4c00-b968-d49d66001e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
