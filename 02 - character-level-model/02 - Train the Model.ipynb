{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1deaca9e-e61b-4250-83a5-48b598cf9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86cdca-2d51-4511-b110-6d67fc1ab74a",
   "metadata": {},
   "source": [
    "# I. Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc890a9a-627a-4a6f-b9d7-b7f82208c83d",
   "metadata": {},
   "source": [
    "#### a. create the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f17ac80-3d9b-4ec0-82ca-7550a9f4382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of: 834178 characters.\n",
      "Unique Characters: 97\n"
     ]
    }
   ],
   "source": [
    "## Reading and processing text\n",
    "with open('openpyxl.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "char_set = set(text) # make a set to count the unique characters\n",
    "print('There is a total of:', len(text), 'characters.')\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd635e1-0877-45e8-9633-60170af995ef",
   "metadata": {},
   "source": [
    "#### b. convert into a sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8cb4b3-b430-49df-977f-786c10ade914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding <def get_type> ==> [69 70 71  1 72 70 85 64 85 90 81 70]\n",
      "Decoding <[69 70 71  1 72 70 85 64 85 90 81 70]> ==> def get_type\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)} # contains our mapping\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "\n",
    "print(f\"Encoding <{text[:12]}> ==> {text_encoded[:12]}\")\n",
    "print(f\"Decoding <{text_encoded[:12]}> ==> {''.join(char_array[i] for i in text_encoded[:12])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a1073-6cc2-41d7-ab7b-39aea0c57db5",
   "metadata": {},
   "source": [
    "#### c.  divide text into chunks of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc81653-c2e1-41e4-80b7-4391464649cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69-70-71-1-72-70-85-64-85-90-81-70-9-85-13-1-87-66-77-86-70-10-27-0-1-1-1-1-74-71-1-74-84-74-79-84-85-66-79-68  ->  70\n",
      "'def get_type(t, value):\\n    if isinstanc'  ->  'e'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "# define sequence: sliding windows through the data\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded)-chunk_size+1)] \n",
    "\n",
    "## inspection:\n",
    "for seq in text_chunks[:1]:\n",
    "    input_seq = seq[:seq_length]\n",
    "    target = seq[seq_length] \n",
    "    \n",
    "print('-'.join(str(el) for el in input_seq), ' -> ', target)\n",
    "print(repr(''.join(char_array[input_seq])),  ' -> ', repr(''.join(char_array[target])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca97aac-97f6-4487-978a-f92731a0ac5d",
   "metadata": {},
   "source": [
    "#### d. build data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58180fb-0244-432a-adaa-560eff861ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\AppData\\Local\\Temp\\ipykernel_12768\\3849331924.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks)) # convert dataset into chunks\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "    \n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks)) # convert dataset into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7b50f7-3019-48ad-b93d-46452f8b5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'def get_type(t, value):\\n    if isinstanc'\n",
      "Target (y): 'ef get_type(t, value):\\n    if isinstance'\n",
      "\n",
      " Input (x): 'ef get_type(t, value):\\n    if isinstance'\n",
      "Target (y): 'f get_type(t, value):\\n    if isinstance('\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(' Input (x):', repr(''.join(char_array[seq])))\n",
    "    print('Target (y):', repr(''.join(char_array[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6d63a27-7136-471a-b355-9b824fb0bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f318612-a1f0-45a1-bd7e-f778a9fa9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Return 2 matrices of 64 vectors each one of size 40. Input vector first 40 and output vector last 40 of a sequence of 41 characters.\n",
    "# sequence -> def get\n",
    "# input -> def ge\n",
    "# output -> ef get\n",
    "# d -> e\n",
    "# de -> f\n",
    "# ...\n",
    "# def ge -> def get\n",
    "\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613340c4-3211-4b39-9d64-9cd6d55c1ea1",
   "metadata": {},
   "source": [
    "# II. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ba73ed8-7fba-4182-b02d-cf137588df6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(97, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=97, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim) \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden.to(device), cell.to(device)\n",
    "    \n",
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size) \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712e0d7e-1a0e-4c3c-ae2a-281fb7ab50bb",
   "metadata": {},
   "source": [
    "# III. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0786bd-f856-4fcd-8f46-fa105fb6b350",
   "metadata": {},
   "source": [
    "#### a. partailly train the model\n",
    "Given a vector X. The output vector is of size 97 containing a probability associated with each character of the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c1ab294-665b-4981-bdba-78af512715c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.5427\n",
      "Epoch 500 loss: 0.9463\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 501\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')\n",
    "\n",
    "pred, hidden, cell = model(seq_batch[:, c], hidden, cell) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dfae08-e9ad-4692-87a7-17052ff11a02",
   "metadata": {},
   "source": [
    "For each epoch we will go randomly through a batch of 64 sequences. Then we will go through each sequence (at once) passing sucessively the i-th character of the sequence. The embedding will make a good representation of each integer of the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a1d1b55-0ddc-4f37-a980-65e1db31d4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66, 77, 74, 72, 79, 78, 70, 79, 85, 16, 31,  0,  1,  1,  1,  1, 29, 67,\n",
       "        80, 83, 69, 70, 83, 31,  0,  1,  1,  1,  1,  1,  1, 29, 77, 70, 71, 85,\n",
       "        16, 31,  0,  1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e608b9f9-ca15-468a-8432-26b9f3d4449b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alignment/>\\n    <border>\\n      <left/>\\n '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = \"\".join(str(char_array[j]) for j in seq_batch[1])\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65085166-1a39-488a-8cd0-5efad01b91bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'66-77-74-72-79-78-70-79-85-16-31-0-1-1-1-1-29-67-80-83-69-70-83-31-0-1-1-1-1-1-1-29-77-70-71-85-16-31-0-1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we pass successively each character of the sequence\n",
    "'-'.join(str(seq_batch[1, c].item()) for c in range(seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfea1e0a-3d60-45f2-b531-d5bd0b4845be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([77, 74, 72, 79, 78, 70, 79, 85, 16, 31,  0,  1,  1,  1,  1, 29, 67, 80,\n",
       "        83, 69, 70, 83, 31,  0,  1,  1,  1,  1,  1,  1, 29, 77, 70, 71, 85, 16,\n",
       "        31,  0,  1,  1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4639ecd8-a22d-405e-8d65-da48cf57b854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1245,  0.0489, -2.6509, -0.5982, -2.5322, -2.9296, -6.3309, -6.1606,\n",
       "         0.5573,  0.3158,  0.2778,  4.2142, -4.7120, -2.4285, -4.3358, -1.9903,\n",
       "        -6.2573,  0.2355, -0.6779, -4.3647, -2.4662, -3.9219, -2.3750, -0.2091,\n",
       "        -3.3720, -4.4933, -3.7280,  0.3501, -6.0850, -3.3400, -0.2872, -7.3120,\n",
       "        -1.2690, -2.2167, -1.0912, -3.0538, -3.5304, -1.1028, -3.4811, -1.1156,\n",
       "        -5.0963, -4.3124, -2.8485, -5.8801, -6.5585, -1.9057, -1.9401, -0.0290,\n",
       "        -1.9691, -2.2149, -7.6845, -1.2522, -1.8178, -0.9566, -4.5071, -3.4762,\n",
       "        -3.6400, -2.8625, -3.9558, -4.4462,  0.1113, -2.7414, -1.7847, -4.1110,\n",
       "         1.7682, -4.0836,  1.5958, -1.7733,  0.8026,  0.2151,  4.7465,  0.6532,\n",
       "        -0.6007, -2.3480,  1.6775, -5.3684,  3.8451, -0.8640,  2.3995,  2.5504,\n",
       "         2.2107,  3.2204, -2.0138,  2.9113,  4.9218,  1.9882, -2.6164,  2.3710,\n",
       "         1.4099,  3.6283, -0.1290, -2.3222, -0.4279, -4.3806, -4.7737, -6.2720,\n",
       "        -6.5861], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction associated with the sequence '13-1-...34'\n",
    "pred[0] # logit for each word in the vocab, which is the most probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8ebe7e-6e87-4ad7-9d7c-f8cdd63aa4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable item val=4.922, index=84.\n"
     ]
    }
   ],
   "source": [
    "i = pred[0].argmax().item()\n",
    "val = pred[0][i]\n",
    "print(f\"Most probable item val={val:.3f}, index={i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f430bbe-aa4c-4df0-9e9c-6d8c2bdc72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_char -> s True_char ->  \n"
     ]
    }
   ],
   "source": [
    "pred_char = char_array[i]\n",
    "true_char = char_array[target_batch[1][-1]]\n",
    "print('pred_char ->', pred_char, 'True_char ->', true_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f97e0aa-bf06-4a19-98b8-2dfb549def45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model (partial model)\n",
    "torch.save(model.state_dict(), 'partial_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f7ce54-2152-42b9-ab40-b9983b701816",
   "metadata": {},
   "source": [
    "#### b. save partially trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32c68d01-b909-405f-a5be-b55c456e4910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(97, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=97, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "model.load_state_dict(torch.load('partial_model.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "635832fc-537c-4a9e-a0f6-06dab6cb6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(seq):\n",
    "    print(\"-\".join(str(el.item()) for el in seq))\n",
    "    return \"\".join(char_array[j] for j in seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eafce0b3-a112-4df0-9226-c0aecbe43b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66-77-74-72-79-78-70-79-85-16-31-0-1-1-1-1-29-67-80-83-69-70-83-31-0-1-1-1-1-1-1-29-77-70-71-85-16-31-0-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alignment/>\\n    <border>\\n      <left/>\\n '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(seq_batch[1]) # input seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ee5f9dd-93cf-4818-8bad-bc17858801ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77-74-72-79-78-70-79-85-16-31-0-1-1-1-1-29-67-80-83-69-70-83-31-0-1-1-1-1-1-1-29-77-70-71-85-16-31-0-1-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lignment/>\\n    <border>\\n      <left/>\\n  '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(target_batch[1]) # output seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "868a85c3-2c0a-4dbc-91d2-dae98f907833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last character prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "838f5123-c821-4d81-87e1-31f5a0ccd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, hidden, cell = model(seq_batch[:, -1], hidden, cell) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30e8aa16-4d74-4ab2-8a06-5aa2ed7a63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1035, -0.7862, -1.4581,  0.4942, -0.9661, -1.0190, -6.3753, -5.4056,\n",
       "         1.1921,  1.6248,  0.4791,  3.7483, -4.0674, -1.8715, -4.2060, -1.2852,\n",
       "        -5.8493,  0.0992, -0.4466, -4.4085, -2.3427, -3.1154, -1.4382, -0.4925,\n",
       "        -2.7121, -3.1308, -2.1250,  1.5444, -5.1638, -3.5885, -1.0242, -6.2112,\n",
       "         1.8063, -1.1311, -0.2573, -2.0556, -2.1473, -0.4185, -2.9109,  0.1957,\n",
       "        -5.0529, -3.2311, -2.8833, -5.0160, -5.1881, -2.1661, -0.7307,  0.4137,\n",
       "        -2.3973, -1.0966, -6.8419, -0.3958,  0.0214, -0.8122, -4.5089, -2.2260,\n",
       "        -1.8051, -2.4980, -2.5969, -3.6495,  1.9037, -1.1061, -1.5899, -2.0148,\n",
       "         1.9990, -3.0049, -0.3741, -1.1033,  1.0346, -0.1056,  4.2064,  0.9622,\n",
       "        -1.7771, -1.8486,  1.0415, -3.5869,  3.3563, -0.7338,  2.1549,  1.7562,\n",
       "         0.6947,  3.2622, -1.6808,  1.7336,  5.0644,  0.7114, -2.5878,  1.9146,\n",
       "         2.1550,  2.3643, -1.2161, -2.7538, -0.6194, -3.1247, -3.3311, -4.9865,\n",
       "        -5.4289], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33160a44-65ef-4bde-806f-833adf818017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable item val=5.064, index=84.\n"
     ]
    }
   ],
   "source": [
    "i = pred[0].argmax().item()\n",
    "val = pred[0][i]\n",
    "print(f\"Most probable item val={val:.3f}, index={i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "929d250a-67c5-464f-9042-4d96a1c935c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_char -> s True_char ->  \n"
     ]
    }
   ],
   "source": [
    "pred_char = char_array[i]\n",
    "true_char = char_array[target_batch[1][-1]]\n",
    "print('pred_char ->', pred_char, 'True_char ->', true_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172d831-8f69-4b6c-a0fe-8c18f33bacfe",
   "metadata": {},
   "source": [
    "### c. fully train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49460e6d-9a9b-44e3-9af9-d36b0e3fd5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.5427\n",
      "Epoch 500 loss: 0.9463\n",
      "Epoch 1000 loss: 0.8106\n",
      "Epoch 1500 loss: 0.8181\n",
      "Epoch 2000 loss: 0.7479\n",
      "Epoch 2500 loss: 0.7963\n",
      "Epoch 3000 loss: 0.7100\n",
      "Epoch 3500 loss: 0.6763\n",
      "Epoch 4000 loss: 0.7382\n",
      "Epoch 4500 loss: 0.6336\n",
      "Epoch 5000 loss: 0.7140\n",
      "Epoch 5500 loss: 0.7821\n",
      "Epoch 6000 loss: 0.8590\n",
      "Epoch 6500 loss: 0.7630\n",
      "Epoch 7000 loss: 0.7782\n",
      "Epoch 7500 loss: 0.7442\n",
      "Epoch 8000 loss: 0.8220\n",
      "Epoch 8500 loss: 0.8846\n",
      "Epoch 9000 loss: 0.8854\n",
      "Epoch 9500 loss: 0.8589\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size) \n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 10000\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')\n",
    "\n",
    "# save the model (partial model)\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ab4ee-4d52-493e-9f01-7651f8b31135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
